{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import random \n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of data_files: 81200\n",
      "First 10 data_fiels ['graph_0.pt', 'graph_1.pt', 'graph_2.pt', 'graph_3.pt', 'graph_4.pt', 'graph_5.pt', 'graph_6.pt', 'graph_7.pt', 'graph_8.pt', 'graph_9.pt']\n",
      "Length of list_of_iso_graphs: 811\n",
      "length of each iso list : 100\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"data/task_from_graph_tensor/\"\n",
    "data_files = os.listdir(data_directory)\n",
    "data_files = natsorted(data_files)\n",
    "print(f\"Lenght of data_files: {len(data_files)}\")\n",
    "print(f\"First 10 data_fiels {data_files[:10]}\")\n",
    "\n",
    "list_of_iso_graphs = [] # List of all unique graphs\n",
    "list_of_same_graphs = [] # Graph having the same structure iso\n",
    "for idx, data_file in enumerate(data_files):\n",
    "    data = torch.load(data_directory + data_file)\n",
    "    if idx % 100 == 0 and idx != 0:\n",
    "        list_of_iso_graphs.append(list_of_same_graphs.copy())\n",
    "        list_of_same_graphs.clear()\n",
    "        list_of_same_graphs.append(data)\n",
    "    else: \n",
    "        list_of_same_graphs.append(data)\n",
    "\n",
    "print(f\"Length of list_of_iso_graphs: {len(list_of_iso_graphs)}\")\n",
    "print(f\"length of each iso list : {len(list_of_iso_graphs[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test data: 20\n",
      "Lenght of train data: 791\n"
     ]
    }
   ],
   "source": [
    "# Splitting Train and Test\n",
    "random.seed(42)\n",
    "num_test_data = 20\n",
    "list_of_iso_test = random.sample(list_of_iso_graphs, num_test_data)\n",
    "print(f\"Length of test data: {len(list_of_iso_test)}\")\n",
    "list_of_iso_train = [item for item in list_of_iso_graphs if item not in list_of_iso_test]\n",
    "print(f\"Lenght of train data: {len(list_of_iso_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered_iso_train: 791\n",
      "Filtered_iso_test: 20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def filter_data(list_of_iso):\n",
    "    filtered_iso_list = []\n",
    "    for idx, iso_list in enumerate(list_of_iso):\n",
    "        latency_list = []\n",
    "        without_outlier_list = []\n",
    "        for data in iso_list:\n",
    "            latency_list.append(data.y)\n",
    "        latency_array = np.array(latency_list)\n",
    "        q1 = np.percentile(latency_array, 25)\n",
    "        q3 = np.percentile(latency_array, 75)\n",
    "        iqr = q3 - q1\n",
    "        min_val = q1 - 1.5 * iqr\n",
    "        max_val = q3 + 1.5 * iqr\n",
    "        for data in iso_list:\n",
    "            # if data.y > min_val and data.y < max_val: # Removing outliers\n",
    "            if data.y > q1 and data.y < q3: # Removing first and last quartile\n",
    "                without_outlier_list.append(data)\n",
    "        filtered_iso_list.append(without_outlier_list)\n",
    "    return filtered_iso_list\n",
    "\n",
    "filtered_iso_train = filter_data(list_of_iso_train)\n",
    "print(f\"Filtered_iso_train: {len(filtered_iso_train)}\")\n",
    "filtered_iso_test = filter_data(list_of_iso_test)\n",
    "print(f\"Filtered_iso_test: {len(filtered_iso_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(\"data/task_from_graph_filtered_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(filtered_iso_test, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_directory = \"data/task_from_graph_filtered_train/\"\n",
    "count = 0\n",
    "for _, same_graph_list in enumerate(filtered_iso_train):\n",
    "    for idx, data in enumerate(same_graph_list):\n",
    "        torch.save(data, data_directory + f\"{count}.pt\")\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
